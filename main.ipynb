{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter NLP Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1n67ATeDATUrXn0PEmsW4iyE9qI6rhDcv",
      "authorship_tag": "ABX9TyMhHg2C5AbSygmKu78wAMXd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSRCpcR3ulaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91798f9-aaa3-4c51-fe7c-10a0e7c34c44"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tweepy as tw\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import TextVectorization, Normalization, Flatten, Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "!pip install -q -U keras-tuner\n",
        "import keras_tuner as kt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97 kB 4.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5GgpCJGxb8F"
      },
      "source": [
        "pd.set_option('max_colwidth', 1500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjV7DuohluIO"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Twitter NLP Project/Emotions Dataset.csv\", header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwEOgaHVokc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a3ea9d6c-4a1e-45ea-e738-658c901ab9e9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet sentiment\n",
              "0                            i didnt feel humiliated   sadness\n",
              "1  i can go from feeling so hopeless to so damned...   sadness\n",
              "2   im grabbing a minute to post i feel greedy wrong     anger\n",
              "3  i am ever feeling nostalgic about the fireplac...      love\n",
              "4                               i am feeling grouchy     anger"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpJ2NdiFu22y"
      },
      "source": [
        "Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGN4hFKDNUGB"
      },
      "source": [
        "# Encoding each label\n",
        "def label_encode(data,label):\n",
        "    labels=data[label].map(\n",
        "    {\n",
        "        \"joy\":0,\n",
        "        \"sadness\":1,\n",
        "        \"anger\":2,\n",
        "        \"fear\":3,\n",
        "        \"love\":4,\n",
        "        \"surprise\":5\n",
        "    }\n",
        "    )\n",
        "    return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCklIKSsNXa8"
      },
      "source": [
        "df[\"label\"] = label_encode(df, \"sentiment\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "JcfGRcnvNmYs",
        "outputId": "7bd6b803-beec-47df-cb18-78c1e01d0c4b"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>im having ssa examination tomorrow in the morn...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>i constantly worry about their fight against n...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>i feel its important to share this info for th...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>i truly feel that if you are passionate enough...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet sentiment  label\n",
              "0                                i didnt feel humiliated   sadness      1\n",
              "1      i can go from feeling so hopeless to so damned...   sadness      1\n",
              "2       im grabbing a minute to post i feel greedy wrong     anger      2\n",
              "3      i am ever feeling nostalgic about the fireplac...      love      4\n",
              "4                                   i am feeling grouchy     anger      2\n",
              "...                                                  ...       ...    ...\n",
              "19995  im having ssa examination tomorrow in the morn...   sadness      1\n",
              "19996  i constantly worry about their fight against n...       joy      0\n",
              "19997  i feel its important to share this info for th...       joy      0\n",
              "19998  i truly feel that if you are passionate enough...       joy      0\n",
              "19999  i feel like i just wanna buy any cute make up ...       joy      0\n",
              "\n",
              "[20000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOkWKJ5eNhW8"
      },
      "source": [
        "vocab_size = 10000\n",
        "max_length = 280"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgHYc82oN66p"
      },
      "source": [
        "# Function for tokenisation, one_hot encoding and embedding\n",
        "\n",
        "def data_preparation(data,description):\n",
        "    stemmer=PorterStemmer()\n",
        "    \n",
        "    corpus=[]\n",
        "    \n",
        "    for text in data[description]:\n",
        "        text=re.sub(\"[^a-zA-Z]\",\" \",text)\n",
        "        text=text.lower()\n",
        "        text=text.split()\n",
        "        \n",
        "        text=[stemmer.stem(words)\n",
        "             for words in text\n",
        "              if words not in stopwords.words(\"english\")\n",
        "             ]\n",
        "        text=\" \".join(text)\n",
        "        corpus.append(text)\n",
        "        \n",
        "    oneHot_doc=[one_hot(input_text=words,n=vocab_size)\n",
        "               for words in corpus\n",
        "               ]\n",
        "    \n",
        "    embedded_doc=pad_sequences(sequences=oneHot_doc,\n",
        "                              maxlen=max_length,\n",
        "                              padding=\"pre\")\n",
        "    return embedded_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcSOBZkZObqy"
      },
      "source": [
        "X = data_preparation(df, \"tweet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FGyiDqnOh7L"
      },
      "source": [
        "y = df[\"label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcihnsDqvnj4"
      },
      "source": [
        "Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvcf-5gZv5EH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe39708-d3b8-41aa-f974-6887d63a3b0a"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)\n",
        "\n",
        "print(len(x_train), 'train examples')\n",
        "print(len(x_test), 'test examples')\n",
        "print(len(x_val), 'validation examples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12800 train examples\n",
            "4000 test examples\n",
            "3200 validation examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksOwsEnVxIOa"
      },
      "source": [
        "Build Model and Hyperparameter Tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iREjfyPychFI"
      },
      "source": [
        "# Model builder function for hyperparameter tuning\n",
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  # model.add(keras.layers.Flatten(input_shape=(32, 280)))\n",
        "  model.add(Embedding(input_dim=vocab_size, \n",
        "                      output_dim=hp.Int(\"output_dim:\", min_value=40, max_value=120, step=10), input_length=max_length))\n",
        "\n",
        "  model.add(LSTM(units=128))\n",
        "\n",
        "  # Tune the number of Dense Layers\n",
        "  # Tune the number of units in each layer - between 32-256\n",
        "  # Tune the Dropout rate\n",
        "  \n",
        "  # hp_units = hp.Int('units', min_value=32, max_value=256, step=32)\n",
        "  # model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  \n",
        "\n",
        "  for j in range(hp.Int(\"Dense Layers\", min_value=1, max_value=5, step=1)):\n",
        "        model.add(Dense(units=hp.Int(\"units_\"+str(j), min_value=32, max_value=256, step=32),\n",
        "            activation=\"relu\", kernel_initializer=hp.Choice(\"kernel_init\"+str(j), values=[\"he_uniform\",\"he_normal\"]))   \n",
        "        )\n",
        "        model.add(Dropout(rate=hp.Float(\"drop_rate\"+str(j), min_value=0.1, max_value=0.5, step=0.1))\n",
        "        )\n",
        "  \n",
        "  # Output layer\n",
        "  model.add(Dense(6, activation=\"softmax\"))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  \n",
        "  model.compile(optimizer=Adam(learning_rate=hp.Choice(\"learnRate\", values=[0.01,0.001,0.0001])),\n",
        "        loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiQA9Zlgc0sa"
      },
      "source": [
        "# Instantiate the tuner and perform hypertuning\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='twitter_NLP')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDRo9WFmnwPJ"
      },
      "source": [
        "tuner=kt.tuners.RandomSearch(\n",
        "    model_builder,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=2,\n",
        "    executions_per_trial=2,\n",
        "    directory=\"twitter_NLP2\",\n",
        "    project_name=\"hypertuningNLP\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCOrXS-ic70f"
      },
      "source": [
        "# Early Stopping\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAeb_aJmc_ai",
        "outputId": "864cf9df-06e0-4a98-d860-a52ac55bbb7c"
      },
      "source": [
        "# Perforamnce Hyperparameter tuning\n",
        "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val), callbacks=[stop_early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 20m 06s]\n",
            "val_accuracy: 0.8690625131130219\n",
            "\n",
            "Best val_accuracy So Far: 0.8770312368869781\n",
            "Total elapsed time: 00h 42m 55s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKH5uanWeD-0",
        "outputId": "ace9497e-a825-4c67-e58f-9875795d4329"
      },
      "source": [
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"Dense Layers: \", best_hps.get(\"Dense Layers\"))\n",
        "print(\"drop_rate0: \", best_hps.get(\"drop_rate0\"))\n",
        "print(\"learnRate: \", best_hps.get(\"learnRate\"))\n",
        "print(\"units_0: \", best_hps.get(\"units_0\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense Layers:  3\n",
            "drop_rate0:  0.2\n",
            "learnRate:  0.001\n",
            "units_0:  32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__H2tFAKeL_j"
      },
      "source": [
        "Optimal Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vqz0ODTeJ3q",
        "outputId": "49f024b9-c14d-4141-ee6f-3475dbfabe9f"
      },
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(x_train, y_train, epochs=50, validation_data=(x_val, y_val), callbacks=[stop_early])\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "400/400 [==============================] - 128s 316ms/step - loss: 1.2950 - accuracy: 0.4884 - val_loss: 0.8124 - val_accuracy: 0.7184\n",
            "Epoch 2/50\n",
            "400/400 [==============================] - 127s 317ms/step - loss: 0.5768 - accuracy: 0.8004 - val_loss: 0.4946 - val_accuracy: 0.8378\n",
            "Epoch 3/50\n",
            "400/400 [==============================] - 127s 317ms/step - loss: 0.3411 - accuracy: 0.8887 - val_loss: 0.4219 - val_accuracy: 0.8691\n",
            "Epoch 4/50\n",
            "400/400 [==============================] - 127s 317ms/step - loss: 0.2394 - accuracy: 0.9185 - val_loss: 0.4749 - val_accuracy: 0.8778\n",
            "Epoch 5/50\n",
            "400/400 [==============================] - 128s 320ms/step - loss: 0.1900 - accuracy: 0.9393 - val_loss: 0.4722 - val_accuracy: 0.8759\n",
            "Epoch 6/50\n",
            "400/400 [==============================] - 127s 318ms/step - loss: 0.1493 - accuracy: 0.9531 - val_loss: 0.5123 - val_accuracy: 0.8775\n",
            "Epoch 7/50\n",
            "400/400 [==============================] - 127s 316ms/step - loss: 0.1225 - accuracy: 0.9605 - val_loss: 0.5747 - val_accuracy: 0.8722\n",
            "Epoch 8/50\n",
            "400/400 [==============================] - 127s 318ms/step - loss: 0.1014 - accuracy: 0.9675 - val_loss: 0.5964 - val_accuracy: 0.8709\n",
            "Best epoch: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FFuBmg1eZfx",
        "outputId": "9e0bcbb0-8f8c-450a-fae8-b15926a25ccd"
      },
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model with best number of epochs\n",
        "hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_data=(x_val, y_val), callbacks=[stop_early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "400/400 [==============================] - 129s 319ms/step - loss: 1.4500 - accuracy: 0.3892 - val_loss: 1.0957 - val_accuracy: 0.6131\n",
            "Epoch 2/4\n",
            "400/400 [==============================] - 127s 318ms/step - loss: 0.6557 - accuracy: 0.7814 - val_loss: 0.4732 - val_accuracy: 0.8384\n",
            "Epoch 3/4\n",
            "400/400 [==============================] - 127s 318ms/step - loss: 0.3390 - accuracy: 0.8876 - val_loss: 0.4405 - val_accuracy: 0.8741\n",
            "Epoch 4/4\n",
            "400/400 [==============================] - 127s 317ms/step - loss: 0.2304 - accuracy: 0.9284 - val_loss: 0.4446 - val_accuracy: 0.8891\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb42d710090>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcGqujrLeZic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cdcab6d-e661-44e0-cab3-02a449ac794d"
      },
      "source": [
        "eval_result = hypermodel.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 11s 85ms/step - loss: 0.4495 - accuracy: 0.8802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olZbE40OeZk4",
        "outputId": "a0bdbd5a-ae3c-406a-9e86-0786c6fa8166"
      },
      "source": [
        "print(f\"test loss: {eval_result[0]:.4f}\")\n",
        "print(f\"test accuracy: {eval_result[1]:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 0.4495\n",
            "test accuracy: 0.8802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SRGhjOwyz28"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5y3TTj-7bdF"
      },
      "source": [
        "Predictions on new tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbYi24Rqw17H"
      },
      "source": [
        "# Set up tweepy authorisation\n",
        "\n",
        "api_key = \"X\"\n",
        "api_key_secret = \"X\"\n",
        "access_token = \"X\"\n",
        "access_token_secret = \"X\"\n",
        "\n",
        "auth = tw.OAuthHandler(api_key, api_key_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth,wait_on_rate_limit=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atraopqXGwnV"
      },
      "source": [
        "# Define the search term and the date_since date as variables\n",
        "# Exlcuding retweets\n",
        "search_words = \"#WOLBRE -filter:retweets\"\n",
        "date_since = \"2021-09-06\"\n",
        "count = 10\n",
        "\n",
        "try:\n",
        "  # Collect tweets\n",
        "  tweets = tw.Cursor(api.search,\n",
        "                q=search_words,\n",
        "                lang=\"en\",\n",
        "                since=date_since).items(count)\n",
        "\n",
        "\n",
        "  # Collect tweets, username, location and timestamp\n",
        "  tweet_info = [[tweet.text, tweet.user.screen_name, tweet.user.location, tweet.created_at] for tweet in tweets]\n",
        "\n",
        "  tweet_df = pd.DataFrame(data=tweet_info, \n",
        "                      columns=['tweet', 'user', 'location', 'timestamp'])\n",
        "  \n",
        "  tweet_df['timestamp'] = tweet_df['timestamp'].dt.strftime('%d-%m-%Y %H:%M:%S')\n",
        "\n",
        "\n",
        "except BaseException as e:\n",
        "  print('failed on_status,',str(e))\n",
        "  time.sleep(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXmL8FW52rGW"
      },
      "source": [
        "# Function for different twitter queries\n",
        "def twitter_search(query_term):\n",
        "\n",
        "  search_words = (query_term+\" -filter:retweets -filter:replies\")\n",
        "  date_since = \"2021-09-06\"\n",
        "  count = 10\n",
        "\n",
        "  try:\n",
        "    # Collect tweets\n",
        "    tweets = tw.Cursor(api.search,\n",
        "                  q=search_words,\n",
        "                  lang=\"en\",\n",
        "                  since=date_since).items(count)\n",
        "\n",
        "\n",
        "    # Collect tweets, username, location and timestamp\n",
        "    tweet_info = [[tweet.text, tweet.user.screen_name, tweet.user.location, tweet.created_at] for tweet in tweets]\n",
        "\n",
        "    tweet_df = pd.DataFrame(data=tweet_info, \n",
        "                        columns=['tweet', 'user', 'location', 'timestamp'])\n",
        "    \n",
        "    tweet_df['timestamp'] = tweet_df['timestamp'].dt.strftime('%d-%m-%Y %H:%M:%S')\n",
        "\n",
        "\n",
        "  except BaseException as e:\n",
        "    print('failed on_status,',str(e))\n",
        "    time.sleep(3)\n",
        "\n",
        "  return tweet_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "sPD3Ry7p2816",
        "outputId": "f6782bed-9b39-4829-977d-c1deccdd32c7"
      },
      "source": [
        "twitter_search('Benrahma')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>user</th>\n",
              "      <th>location</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi there,\\nDo you need modern and unique minimalist Logo design?\\nPlease order here. https://t.co/ea6ayWzRyp‚Ä¶ https://t.co/EbyZhnJq91</td>\n",
              "      <td>bishajikumar50</td>\n",
              "      <td>Dhaka, Bangladesh</td>\n",
              "      <td>18-09-2021 12:29:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Also Brentford brilliant to watch. Changed the system to a back 3 after being 433 for so long and let‚Äôs not forget‚Ä¶ https://t.co/vlZ1lD314R</td>\n",
              "      <td>Higginbotham05</td>\n",
              "      <td>andy@tripleamedia.com</td>\n",
              "      <td>18-09-2021 12:28:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Brentford sold Watkins and Benrahma for 60M and bought Ivan Toney who has already outscored both former Brentford f‚Ä¶ https://t.co/6Vhpb3YYIu</td>\n",
              "      <td>CazorlaRoba</td>\n",
              "      <td>Nairobi, Kenya</td>\n",
              "      <td>18-09-2021 12:20:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8 players playing in FPL this week:\\n\\nTsimikas won't start\\nGrealish may be rested\\nBenrahma injured\\nSemedo Wolves https://t.co/h5TPOF1awU</td>\n",
              "      <td>akshayt19nayak</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>18-09-2021 12:18:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>West Ham take on Manchester United, Benrahma Injury and that night in Zagreb: https://t.co/3dgeLHtR0l</td>\n",
              "      <td>WHUNewsApp</td>\n",
              "      <td>Boleyn Ground</td>\n",
              "      <td>18-09-2021 12:17:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Yeah and I benched him hopefully Benrahma can‚Äôt go https://t.co/lcm3NDPCSw</td>\n",
              "      <td>krishdatwani</td>\n",
              "      <td>üáÆüá≥üá¨üá≠</td>\n",
              "      <td>18-09-2021 12:15:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Please be injured Benrahma. Please.</td>\n",
              "      <td>FPL_Bono</td>\n",
              "      <td>England, United Kingdom</td>\n",
              "      <td>18-09-2021 12:11:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>My team tomorrow if Benrahma out:\\nAreola \\nDiop\\nOgbonna \\nZouma\\nCoufal \\nMasuaku\\nSoucek\\nRice\\nBowen \\nVlasic\\nFornals</td>\n",
              "      <td>westhamonline5</td>\n",
              "      <td></td>\n",
              "      <td>18-09-2021 12:11:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Hi there,\\nDo you need modern and unique minimalist Logo design?\\nPlease order here. https://t.co/ea6ayWzRyp‚Ä¶ https://t.co/HODJrRK4gA</td>\n",
              "      <td>bishajikumar50</td>\n",
              "      <td>Dhaka, Bangladesh</td>\n",
              "      <td>18-09-2021 12:11:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sell Benrahma for a profit, buy back Toney at a discount?\\n\\nGaining 0.2 (maybe) while missing out on over 30 points.‚Ä¶ https://t.co/H2PUg4adPF</td>\n",
              "      <td>WaltSaysStuff</td>\n",
              "      <td></td>\n",
              "      <td>18-09-2021 12:09:51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                            tweet  ...            timestamp\n",
              "0           Hi there,\\nDo you need modern and unique minimalist Logo design?\\nPlease order here. https://t.co/ea6ayWzRyp‚Ä¶ https://t.co/EbyZhnJq91  ...  18-09-2021 12:29:45\n",
              "1     Also Brentford brilliant to watch. Changed the system to a back 3 after being 433 for so long and let‚Äôs not forget‚Ä¶ https://t.co/vlZ1lD314R  ...  18-09-2021 12:28:36\n",
              "2    Brentford sold Watkins and Benrahma for 60M and bought Ivan Toney who has already outscored both former Brentford f‚Ä¶ https://t.co/6Vhpb3YYIu  ...  18-09-2021 12:20:28\n",
              "3    8 players playing in FPL this week:\\n\\nTsimikas won't start\\nGrealish may be rested\\nBenrahma injured\\nSemedo Wolves https://t.co/h5TPOF1awU  ...  18-09-2021 12:18:25\n",
              "4                                           West Ham take on Manchester United, Benrahma Injury and that night in Zagreb: https://t.co/3dgeLHtR0l  ...  18-09-2021 12:17:34\n",
              "5                                                                      Yeah and I benched him hopefully Benrahma can‚Äôt go https://t.co/lcm3NDPCSw  ...  18-09-2021 12:15:02\n",
              "6                                                                                                             Please be injured Benrahma. Please.  ...  18-09-2021 12:11:42\n",
              "7                      My team tomorrow if Benrahma out:\\nAreola \\nDiop\\nOgbonna \\nZouma\\nCoufal \\nMasuaku\\nSoucek\\nRice\\nBowen \\nVlasic\\nFornals  ...  18-09-2021 12:11:41\n",
              "8           Hi there,\\nDo you need modern and unique minimalist Logo design?\\nPlease order here. https://t.co/ea6ayWzRyp‚Ä¶ https://t.co/HODJrRK4gA  ...  18-09-2021 12:11:10\n",
              "9  Sell Benrahma for a profit, buy back Toney at a discount?\\n\\nGaining 0.2 (maybe) while missing out on over 30 points.‚Ä¶ https://t.co/H2PUg4adPF  ...  18-09-2021 12:09:51\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85WgH2y91b2a"
      },
      "source": [
        "Function which takes a single sentence and predicts the setiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKX4DhULp6uJ"
      },
      "source": [
        "def predict_new_sentence(model):\n",
        "\n",
        "  new_sentence = input(\"Enter a sentence: \")\n",
        "\n",
        "  tweet_df = pd.DataFrame([new_sentence], columns=['tweet'])\n",
        "  tweet_df[\"prediction\"] = \"\"\n",
        "\n",
        "  X = data_preparation(tweet_df, \"tweet\")\n",
        "\n",
        "  prediction = model.predict(X)\n",
        "\n",
        "  y_pred=[np.argmax(label) for label in prediction]\n",
        "\n",
        "  predict=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
        "\n",
        "  predict[\"Predicted Label\"]=predict[\"Predicted\"].map(\n",
        "      {0:\"joy\", 1:\"sadness\", 2:\"anger\", 3:\"fear\", 4:\"love\", 5:\"surprise\"})\n",
        "\n",
        "  predict_df=pd.concat([tweet_df[\"tweet\"], predict[\"Predicted Label\"]],\n",
        "                    axis=1)\n",
        "  \n",
        "  return predict_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "m64u2qbcigxT",
        "outputId": "16aae10a-4a29-401a-ad5b-4f8314879ac7"
      },
      "source": [
        "predict_new_sentence(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a sentence: He feels like green and blue are just so happy and kind of brilliant.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>Predicted Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He feels like green and blue are just so happy and kind of brilliant.</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                   tweet Predicted Label\n",
              "0  He feels like green and blue are just so happy and kind of brilliant.             joy"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr6kBJwa1ghu"
      },
      "source": [
        "Function which takes a dataframe of tweets and predicts the setiment for each tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IAwAE3UzF1e"
      },
      "source": [
        "def predict_tweets(model, dataframe):\n",
        "  X = data_preparation(tweet_df, \"tweet\")\n",
        "\n",
        "  predictions = []\n",
        "\n",
        "  for tweet in X:\n",
        "    \n",
        "    prediction = model.predict(X)\n",
        "\n",
        "    y_pred=[np.argmax(label) for label in prediction]\n",
        "\n",
        "    predict=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
        "\n",
        "    predict[\"Predicted Label\"] =  predict[\"Predicted\"].map(\n",
        "        {0:\"joy\", 1:\"sadness\", 2:\"anger\", 3:\"fear\", 4:\"love\", 5:\"surprise\"})\n",
        "\n",
        "\n",
        "  predict_df=pd.concat([tweet_df[\"tweet\"], predict[\"Predicted Label\"]],\n",
        "                  axis=1)\n",
        "  \n",
        "  return predict_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "jv-TQSWJy4hE",
        "outputId": "2c1d152a-9f89-4a8e-efde-71dc401b87a0"
      },
      "source": [
        "predict_tweets(model, tweet_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>Predicted Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Who‚Äôs a better strikerüëáüèø\\n‚ù§Ô∏è for Ivan Toney\\nüîÉ for Anthony Martial  #WOLBRE https://t.co/c0IFmzXpMw</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My Prediction \\n\\nFT: Wolves 3 - 3 Brentford \\n\\n#WOLBRE</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>when you think your life is bad\\n\\njust think about those who bought Raul Jimenez in FPL‚Ä¶ #WOLBRE https://t.co/mjVAlG7xkq</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Against #MUFC, #Wolves played like they would be earning 15pts in that game, they gave everything with high tempo f‚Ä¶ https://t.co/Ok5Xr5TXzp</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ivan Toney is on üî•üî•! \\nGet in there....\\n#FPL #WOLBRE @BigManBakar</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Mastering Chelsea‚Äôs system isn‚Äôt easy or wolves are shit take ur pick #WOLBRE</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Shit at the back. Shit in front of goal.\\n\\nüê∫üêù #WOLBRE #WWFC</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Okay, Brentford are def legit. #WOLBRE</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Jimenez is wasteful #WOLBRE</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Brentford look like the real deal #WOLBRE</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                          tweet Predicted Label\n",
              "0                                           Who‚Äôs a better strikerüëáüèø\\n‚ù§Ô∏è for Ivan Toney\\nüîÉ for Anthony Martial  #WOLBRE https://t.co/c0IFmzXpMw             joy\n",
              "1                                                                                      My Prediction \\n\\nFT: Wolves 3 - 3 Brentford \\n\\n#WOLBRE           anger\n",
              "2                     when you think your life is bad\\n\\njust think about those who bought Raul Jimenez in FPL‚Ä¶ #WOLBRE https://t.co/mjVAlG7xkq            love\n",
              "3  Against #MUFC, #Wolves played like they would be earning 15pts in that game, they gave everything with high tempo f‚Ä¶ https://t.co/Ok5Xr5TXzp             joy\n",
              "4                                                                            Ivan Toney is on üî•üî•! \\nGet in there....\\n#FPL #WOLBRE @BigManBakar           anger\n",
              "5                                                                 Mastering Chelsea‚Äôs system isn‚Äôt easy or wolves are shit take ur pick #WOLBRE         sadness\n",
              "6                                                                                  Shit at the back. Shit in front of goal.\\n\\nüê∫üêù #WOLBRE #WWFC           anger\n",
              "7                                                                                                        Okay, Brentford are def legit. #WOLBRE           anger\n",
              "8                                                                                                                   Jimenez is wasteful #WOLBRE           anger\n",
              "9                                                                                                     Brentford look like the real deal #WOLBRE           anger"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIIhfT8a1XiL"
      },
      "source": [
        "# Combining functions to be able to search for a specific term before sentiment analysis\n",
        "\n",
        "def search_and_predict_tweets(query, model):\n",
        "\n",
        "  tweet_df = twitter_search(query)\n",
        "  X = data_preparation(tweet_df, \"tweet\")\n",
        "\n",
        "  predictions = []\n",
        "\n",
        "  for tweet in X:\n",
        "    \n",
        "    prediction = model.predict(X)\n",
        "\n",
        "    y_pred=[np.argmax(label) for label in prediction]\n",
        "\n",
        "    predict=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
        "\n",
        "    predict[\"Predicted Label\"] =  predict[\"Predicted\"].map(\n",
        "        {0:\"joy\", 1:\"sadness\", 2:\"anger\", 3:\"fear\", 4:\"love\", 5:\"surprise\"})\n",
        "\n",
        "\n",
        "  predict_df=pd.concat([tweet_df[\"tweet\"], predict[\"Predicted Label\"]],\n",
        "                  axis=1)\n",
        "  \n",
        "  return predict_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "kzvD1KnU3e_x",
        "outputId": "3a9a5dea-ae73-4485-ca49-49245f2c3707"
      },
      "source": [
        "search_and_predict_tweets('Wolves', model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>Predicted Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wolves have failed to have a shot on target in a Premier League game at Molineux for just the third time since the‚Ä¶ https://t.co/ddJPhHWlzo</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wolves? whoa</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wolves need three unanswered goals in the second half for our first 3u bet to lose.. How are we looking? üëÄ</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mbeumo makes it 2-0 to Brentford against Wolves https://t.co/K3zhd2tEwW https://t.co/jABsaHqdQw</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>First Winter Weather Advisory for Alaska for its 2021-22 Snow season #AKwx #USwx https://t.co/KJh1rP6AJL</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>‚ÄúThis is the week the Wolves will turn it around. They can‚Äôt keep out-chancing their opponents and losing. They‚Äôll‚Ä¶ https://t.co/w0w9qGtzZq</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Wolves wtf??? Smh. .</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Brentford deserving there lead at half-time against Wolves ‚öΩÔ∏è</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Who else doesn‚Äôt own any Wolves assets üôãüèª‚Äç‚ôÇÔ∏è üòâ</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Great 1st half. \\n\\n2-0 away to Wolves. \\n\\nMore of the same for the 2nd half please üêù\\n\\nIvan Toney üî•</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                         tweet Predicted Label\n",
              "0  Wolves have failed to have a shot on target in a Premier League game at Molineux for just the third time since the‚Ä¶ https://t.co/ddJPhHWlzo             joy\n",
              "1                                                                                                                                 wolves? whoa         sadness\n",
              "2                                   Wolves need three unanswered goals in the second half for our first 3u bet to lose.. How are we looking? üëÄ             joy\n",
              "3                                              Mbeumo makes it 2-0 to Brentford against Wolves https://t.co/K3zhd2tEwW https://t.co/jABsaHqdQw             joy\n",
              "4                                     First Winter Weather Advisory for Alaska for its 2021-22 Snow season #AKwx #USwx https://t.co/KJh1rP6AJL            love\n",
              "5  ‚ÄúThis is the week the Wolves will turn it around. They can‚Äôt keep out-chancing their opponents and losing. They‚Äôll‚Ä¶ https://t.co/w0w9qGtzZq           anger\n",
              "6                                                                                                                         Wolves wtf??? Smh. .         sadness\n",
              "7                                                                                Brentford deserving there lead at half-time against Wolves ‚öΩÔ∏è            love\n",
              "8                                                                                               Who else doesn‚Äôt own any Wolves assets üôãüèª‚Äç‚ôÇÔ∏è üòâ         sadness\n",
              "9                                       Great 1st half. \\n\\n2-0 away to Wolves. \\n\\nMore of the same for the 2nd half please üêù\\n\\nIvan Toney üî•             joy"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6CE18wT36dG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}