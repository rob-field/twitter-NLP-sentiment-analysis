{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8200,
     "status": "ok",
     "timestamp": 1632050841625,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "PSRCpcR3ulaa",
    "outputId": "c290728d-82cf-4245-e82a-d05bc4c76d23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 2.x\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tweepy as tw\n",
    "import re\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import TextVectorization, Normalization, Flatten, Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5GgpCJGxb8F"
   },
   "outputs": [],
   "source": [
    "# Set dataframe column width\n",
    "pd.set_option('max_colwidth', 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WjV7DuohluIO"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Emotions Dataset.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1632050842255,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "hwEOgaHVokc1",
    "outputId": "90c10d3d-19f0-4f94-db54-2fb4145e5171"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0                            i didnt feel humiliated   sadness\n",
       "1  i can go from feeling so hopeless to so damned...   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      love\n",
       "4                               i am feeling grouchy     anger"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpJ2NdiFu22y"
   },
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KGN4hFKDNUGB"
   },
   "outputs": [],
   "source": [
    "# Function encoding each label\n",
    "\n",
    "def label_encode(data,label):\n",
    "    labels=data[label].map(\n",
    "    {\n",
    "        \"joy\":0,\n",
    "        \"sadness\":1,\n",
    "        \"anger\":2,\n",
    "        \"fear\":3,\n",
    "        \"love\":4,\n",
    "        \"surprise\":5\n",
    "    }\n",
    "    )\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aCklIKSsNXa8"
   },
   "outputs": [],
   "source": [
    "df[\"label\"] = label_encode(df, \"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1632050849840,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "JcfGRcnvNmYs",
    "outputId": "59e97aa6-6a9b-4339-f850-543f191868c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>im having ssa examination tomorrow in the morn...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>i constantly worry about their fight against n...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>i feel its important to share this info for th...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>i truly feel that if you are passionate enough...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet sentiment  label\n",
       "0                                i didnt feel humiliated   sadness      1\n",
       "1      i can go from feeling so hopeless to so damned...   sadness      1\n",
       "2       im grabbing a minute to post i feel greedy wrong     anger      2\n",
       "3      i am ever feeling nostalgic about the fireplac...      love      4\n",
       "4                                   i am feeling grouchy     anger      2\n",
       "...                                                  ...       ...    ...\n",
       "19995  im having ssa examination tomorrow in the morn...   sadness      1\n",
       "19996  i constantly worry about their fight against n...       joy      0\n",
       "19997  i feel its important to share this info for th...       joy      0\n",
       "19998  i truly feel that if you are passionate enough...       joy      0\n",
       "19999  i feel like i just wanna buy any cute make up ...       joy      0\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "wOkWKJ5eNhW8"
   },
   "outputs": [],
   "source": [
    "# Set vocab size and maximum sentence length\n",
    "vocab_size = 10000\n",
    "max_length = 280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qgHYc82oN66p"
   },
   "outputs": [],
   "source": [
    "# Function for tokenisation, one_hot encoding and padding\n",
    "\n",
    "def data_preparation(data,description):\n",
    "    stemmer=PorterStemmer()\n",
    "    \n",
    "    corpus=[]\n",
    "    \n",
    "    for text in data[description]:\n",
    "        text=re.sub(\"[^a-zA-Z]\",\" \",text)\n",
    "        text=text.lower()\n",
    "        text=text.split()\n",
    "        \n",
    "        text=[stemmer.stem(words)\n",
    "             for words in text\n",
    "              if words not in stopwords.words(\"english\")\n",
    "             ]\n",
    "        text=\" \".join(text)\n",
    "        corpus.append(text)\n",
    "        \n",
    "    oneHot_doc=[one_hot(input_text=words,n=vocab_size)\n",
    "               for words in corpus\n",
    "               ]\n",
    "    \n",
    "    padded_doc=pad_sequences(sequences=oneHot_doc,\n",
    "                              maxlen=max_length,\n",
    "                              padding=\"pre\")\n",
    "    return padded_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HcSOBZkZObqy"
   },
   "outputs": [],
   "source": [
    "X = data_preparation(df, \"tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1FGyiDqnOh7L"
   },
   "outputs": [],
   "source": [
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcihnsDqvnj4"
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1632051151467,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "Jvcf-5gZv5EH",
    "outputId": "750f0bfc-8ea3-47f7-f77b-9a7d8afc68b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800 train examples\n",
      "4000 test examples\n",
      "3200 validation examples\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)\n",
    "\n",
    "# Check train, test, val set size\n",
    "print(len(x_train), 'train examples')\n",
    "print(len(x_test), 'test examples')\n",
    "print(len(x_val), 'validation examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksOwsEnVxIOa"
   },
   "source": [
    "# Build Model and Hyperparameter Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iREjfyPychFI"
   },
   "outputs": [],
   "source": [
    "# Model builder function for hyperparameter tuning\n",
    "\n",
    "def model_builder(hp):\n",
    "    \n",
    "    # Initial Model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Embedding layer\n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                          output_dim=hp.Int(\"output_dim:\", min_value=40, max_value=120, step=10), input_length=max_length))\n",
    "\n",
    "    model.add(LSTM(units=128))\n",
    "\n",
    "    # Tune number of dense layers, layer units and dropout rate\n",
    "\n",
    "    for j in range(hp.Int(\"Dense Layers\", min_value=1, max_value=5, step=1)):\n",
    "        model.add(Dense(units=hp.Int(\"units_\"+str(j), min_value=32, max_value=256, step=32),\n",
    "            activation=\"relu\", kernel_initializer=hp.Choice(\"kernel_init\"+str(j), values=[\"he_uniform\",\"he_normal\"]))   \n",
    "        )\n",
    "    model.add(Dropout(rate=hp.Float(\"drop_rate\"+str(j), min_value=0.1, max_value=0.5, step=0.1))\n",
    "        )\n",
    "  \n",
    "    # Output layer\n",
    "    model.add(Dense(6, activation=\"softmax\"))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice(\"learnRate\", values=[0.01,0.001,0.0001])),\n",
    "            loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDRo9WFmnwPJ"
   },
   "outputs": [],
   "source": [
    "# Instantiate the tuner\n",
    "tuner=kt.tuners.RandomSearch(\n",
    "    model_builder,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=2,\n",
    "    executions_per_trial=2,\n",
    "    directory=\"twitter_NLP2\",\n",
    "    project_name=\"hypertuningNLP\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCOrXS-ic70f"
   },
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAeb_aJmc_ai",
    "outputId": "0a156d01-a867-4e3a-ee2b-6c9d3844ae9a"
   },
   "outputs": [],
   "source": [
    "# Perforamnce Hyperparameter tuning\n",
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1631962369453,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "VKH5uanWeD-0",
    "outputId": "ace9497e-a825-4c67-e58f-9875795d4329"
   },
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Dense Layers: \", best_hps.get(\"Dense Layers\"))\n",
    "print(\"drop_rate0: \", best_hps.get(\"drop_rate0\"))\n",
    "print(\"learnRate: \", best_hps.get(\"learnRate\"))\n",
    "print(\"units_0: \", best_hps.get(\"units_0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__H2tFAKeL_j"
   },
   "source": [
    "# Optimal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Tuner Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1018534,
     "status": "ok",
     "timestamp": 1631963392359,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "7Vqz0ODTeJ3q",
    "outputId": "49f024b9-c14d-4141-ee6f-3475dbfabe9f"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=50, validation_data=(x_val, y_val), callbacks=[stop_early])\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 589900,
     "status": "ok",
     "timestamp": 1631963982450,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "9FFuBmg1eZfx",
    "outputId": "9e0bcbb0-8f8c-450a-fae8-b15926a25ccd"
   },
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model with best number of epochs\n",
    "hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_data=(x_val, y_val), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20558,
     "status": "ok",
     "timestamp": 1631964002990,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "HcGqujrLeZic",
    "outputId": "9cdcab6d-e661-44e0-cab3-02a449ac794d"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "eval_result = hypermodel.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1631964002991,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "olZbE40OeZk4",
    "outputId": "a0bdbd5a-ae3c-406a-9e86-0786c6fa8166"
   },
   "outputs": [],
   "source": [
    "print(f\"test loss: {eval_result[0]:.4f}\")\n",
    "print(f\"test accuracy: {eval_result[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal Model Function\n",
    "def optimal_model_builder():\n",
    "    model = keras.Sequential()\n",
    "    model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "    model.add(LSTM(units=128))\n",
    "    model.add(Dense(6, activation=\"softmax\"))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "            loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "400/400 [==============================] - 114s 282ms/step - loss: 1.5053 - accuracy: 0.3945 - val_loss: 1.1385 - val_accuracy: 0.6059\n",
      "Epoch 2/2\n",
      "400/400 [==============================] - 111s 278ms/step - loss: 0.8334 - accuracy: 0.6874 - val_loss: 0.7494 - val_accuracy: 0.7019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fede829d8d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = optimal_model_builder()\n",
    "model.fit(x_train, y_train, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 13s 104ms/step - loss: 0.7500 - accuracy: 0.7010\n",
      "Accuracy:  70.09999752044678\n",
      "Loss:  0.750033974647522\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Accuracy: ',accuracy*100)\n",
    "print('Loss: ',loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5y3TTj-7bdF"
   },
   "source": [
    "# Predictions on new tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "fbYi24Rqw17H"
   },
   "outputs": [],
   "source": [
    "# Set up tweepy authorisation\n",
    "\n",
    "api_key = \"X\"\n",
    "api_key_secret = \"X\"\n",
    "access_token = \"X\"\n",
    "access_token_secret = \"X\"\n",
    "\n",
    "auth = tw.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "kXmL8FW52rGW"
   },
   "outputs": [],
   "source": [
    "# Function for different twitter queries\n",
    "def twitter_search(query_term):\n",
    "    \n",
    "    # Function takes a search term to use as a query\n",
    "    # Excxlude retweets and replies\n",
    "    date_since = \"2021-01-01\"\n",
    "    search_words = (query_term+f\" -filter:retweets -filter:replies since:{date_since}\")\n",
    "    count = 10\n",
    "\n",
    "    try:\n",
    "        # Collect tweets\n",
    "        tweets = tw.Cursor(api.search_tweets,\n",
    "                      q=search_words,\n",
    "                      lang=\"en\").items(count)\n",
    "\n",
    "\n",
    "        # Collect tweets, username, location and timestamp\n",
    "        tweet_info = [[tweet.text, tweet.user.screen_name, tweet.user.location, tweet.created_at] for tweet in tweets]\n",
    "\n",
    "        # Assing collected information to a dataframe \n",
    "        tweet_df = pd.DataFrame(data=tweet_info, \n",
    "                            columns=['tweet', 'user', 'location', 'timestamp'])\n",
    "\n",
    "        tweet_df['timestamp'] = tweet_df['timestamp'].dt.strftime('%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "\n",
    "    # Incase of exception\n",
    "    except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            time.sleep(3)\n",
    "\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85WgH2y91b2a"
   },
   "source": [
    "# Sentiment analysis using a single, user inputted sentence/phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "fKX4DhULp6uJ"
   },
   "outputs": [],
   "source": [
    "def predict_new_sentence(model):\n",
    "    \n",
    "    new_sentence = input(\"Enter a sentence: \")\n",
    "\n",
    "    tweet_df = pd.DataFrame([new_sentence], columns=['tweet'])\n",
    "    tweet_df[\"prediction\"] = \"\"\n",
    "\n",
    "    X = data_preparation(tweet_df, \"tweet\")\n",
    "\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    y_pred=[np.argmax(label) for label in prediction]\n",
    "\n",
    "    predict=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
    "\n",
    "    predict[\"Predicted Label\"]=predict[\"Predicted\"].map(\n",
    "          {0:\"joy\", 1:\"sadness\", 2:\"anger\", 3:\"fear\", 4:\"love\", 5:\"surprise\"})\n",
    "\n",
    "    predict_df=pd.concat([tweet_df[\"tweet\"], predict[\"Predicted Label\"]],\n",
    "                        axis=1)\n",
    "\n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "executionInfo": {
     "elapsed": 2042,
     "status": "ok",
     "timestamp": 1631966448118,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "m64u2qbcigxT",
    "outputId": "16aae10a-4a29-401a-ad5b-4f8314879ac7"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence:  Hello I am very happy today\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello I am very happy today</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         tweet Predicted Label\n",
       "0  Hello I am very happy today             joy"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_new_sentence(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr6kBJwa1ghu"
   },
   "source": [
    "# Sentiment analysis for a dataframe of sentences/phrases (i.e. tweets), thus combining the twitter api search function and the NLP moodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTOMEZJU3CeN"
   },
   "source": [
    "Firstly using a predefined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "9IAwAE3UzF1e"
   },
   "outputs": [],
   "source": [
    "def predict_tweets(model, dataframe):\n",
    "    X = data_preparation(tweet_df, \"tweet\")\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for tweet in X:\n",
    "\n",
    "        prediction = model.predict(X)\n",
    "\n",
    "        y_pred=[np.argmax(label) for label in prediction]\n",
    "\n",
    "        predict=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
    "\n",
    "        predict[\"Predicted Label\"] =  predict[\"Predicted\"].map(\n",
    "            {0:\"joy\", 1:\"sadness\", 2:\"anger\", 3:\"fear\", 4:\"love\", 5:\"surprise\"})\n",
    "\n",
    "\n",
    "    predict_df=pd.concat([tweet_df[\"tweet\"], predict[\"Predicted Label\"]],\n",
    "                      axis=1)\n",
    "\n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 1168,
     "status": "ok",
     "timestamp": 1631967513027,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "jv-TQSWJy4hE",
    "outputId": "2c1d152a-9f89-4a8e-efde-71dc401b87a0"
   },
   "outputs": [],
   "source": [
    "predict_tweets(model, tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFt6iyvK3GMB"
   },
   "source": [
    "Secondly, combining previous functions to allow sentiment analysis for a query term passed to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "JIIhfT8a1XiL"
   },
   "outputs": [],
   "source": [
    "def search_and_predict_tweets(query, model):\n",
    "\n",
    "    tweet_df = twitter_search(query)\n",
    "    X = data_preparation(tweet_df, \"tweet\")\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for tweet in X:\n",
    "\n",
    "        prediction = model.predict(X)\n",
    "\n",
    "        y_pred=[np.argmax(label) for label in prediction]\n",
    "\n",
    "        predict=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
    "\n",
    "        predict[\"Predicted Label\"] =  predict[\"Predicted\"].map(\n",
    "            {0:\"joy\", 1:\"sadness\", 2:\"anger\", 3:\"fear\", 4:\"love\", 5:\"surprise\"})\n",
    "\n",
    "\n",
    "    predict_df=pd.concat([tweet_df[\"tweet\"], predict[\"Predicted Label\"]],\n",
    "                      axis=1)\n",
    "    print(\"Most Common Emotion(s) expressed:\", predict_df[\"Predicted Label\"].mode()[0])\n",
    "    print(\"\")\n",
    "    \n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 1539,
     "status": "ok",
     "timestamp": 1631968307070,
     "user": {
      "displayName": "Rob Field",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHEhYV7Kkdnf1__igeh_kIthh1_rCLMdGsvHXTEg=s64",
      "userId": "12479626243364181660"
     },
     "user_tz": -60
    },
    "id": "kzvD1KnU3e_x",
    "outputId": "3a9a5dea-ae73-4485-ca49-49245f2c3707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Emotion(s) expressed: anger\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Got 2 days off, gonna start new design of my w...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Everyone dies one day. Everyone. Even wolves....</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oregon police seek clues in poisoning of eight...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wolves https://t.co/CljMDtAj4R</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A total of 8 wolves, including an entire pack,...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Up next, a trip to @Wolves 👊 #WOLLIV ❤️🥰 https...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Wolf telling the Sheep how to avoid Wolves...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oregon officials ask public help to find kille...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Inside you there are two wolves https://t.co/G...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hey folks\\nI've made the decision to keep writ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet Predicted Label\n",
       "0  Got 2 days off, gonna start new design of my w...           anger\n",
       "1  \"Everyone dies one day. Everyone. Even wolves....           anger\n",
       "2  Oregon police seek clues in poisoning of eight...         sadness\n",
       "3                     Wolves https://t.co/CljMDtAj4R           anger\n",
       "4  A total of 8 wolves, including an entire pack,...         sadness\n",
       "5  Up next, a trip to @Wolves 👊 #WOLLIV ❤️🥰 https...            love\n",
       "6  The Wolf telling the Sheep how to avoid Wolves...           anger\n",
       "7  Oregon officials ask public help to find kille...         sadness\n",
       "8  Inside you there are two wolves https://t.co/G...             joy\n",
       "9  Hey folks\\nI've made the decision to keep writ...             joy"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_and_predict_tweets('Wolves', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMNHvWJscChmNU4pQpRjtMF",
   "collapsed_sections": [],
   "mount_file_id": "1n67ATeDATUrXn0PEmsW4iyE9qI6rhDcv",
   "name": "Twitter NLP Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
